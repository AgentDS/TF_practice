{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-614640d4fa8f>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "num_input = 784\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((mnist.train.images,mnist.train.labels))\n",
    "dataset = dataset.repeat().batch(batch_size).prefetch(batch_size)\n",
    "dataset_iter = tfe.Iterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-b1344f76c1ed>:3: Network.__init__ (from tensorflow.contrib.eager.python.network) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please inherit from `tf.keras.Model`, and see its documentation for details. `tf.keras.Model` should be a drop-in replacement for `tfe.Network` in most cases, but note that `track_layer` is no longer necessary or supported. Instead, `Layer` instances are tracked on attribute assignment (see the section of `tf.keras.Model`'s documentation on subclassing). Since the output of `track_layer` is often assigned to an attribute anyway, most code can be ported by simply removing the `track_layer` calls.\n",
      "\n",
      "`tf.keras.Model` works with all TensorFlow `Layer` instances, including those from `tf.layers`, but switching to the `tf.keras.layers` versions along with the migration to `tf.keras.Model` is recommended, since it will preserve variable names. Feel free to import it with an alias to avoid excess typing :).\n",
      "WARNING:tensorflow:** tfe.Network is deprecated and will be removed in a future version.\n",
      "\n",
      "Please inherit from `tf.keras.Model`, and see its documentation for details. `tf.keras.Model` should be a drop-in replacement for `tfe.Network` in most cases, but note that `track_layer` is no longer necessary or supported. Instead, `Layer` instances are tracked on attribute assignment (see the section of `tf.keras.Model`'s documentation on subclassing). Since the output of `track_layer` is often assigned to an attribute anyway, most code can be ported by simply removing the `track_layer` calls.\n",
      "\n",
      "`tf.keras.Model` works with all TensorFlow `Layer` instances, including those from `tf.layers`, but switching to the `tf.keras.layers` versions along with the migration to `tf.keras.Model` is recommended, since it will preserve variable names. Feel free to import it with an alias to avoid excess typing :).\n"
     ]
    }
   ],
   "source": [
    "class NeuralNet(tfe.Network):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet,self).__init__()\n",
    "        self.layer1 = self.track_layer(tf.layers.Dense(n_hidden_1,activation=tf.nn.relu))\n",
    "        self.layer2 = self.track_layer(tf.layers.Dense(n_hidden_2,activation=tf.nn.relu))\n",
    "        self.out_layer = self.track_layer(tf.layers.Dense(num_classes))\n",
    "        \n",
    "    def call(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return self.out_layer(x)\n",
    "    \n",
    "neural_net = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(inference_fn,inputs,labels):\n",
    "    return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                             logits=inference_fn(inputs),labels=labels))\n",
    "def accuracy_fn(inference_fn,inputs,labels):\n",
    "    prediction = tf.nn.softmax(inference_fn(inputs))\n",
    "    correct_pred = tf.equal(tf.argmax(prediction,1),labels)\n",
    "    return tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "grad = tfe.implicit_gradients(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss=2.368701935\n",
      "Step: 0001  loss= 2.368701935  accuracy= 0.1016\n",
      "Step: 0100  loss= 0.574926794  accuracy= 0.8311\n",
      "Step: 0200  loss= 0.245345071  accuracy= 0.9287\n",
      "Step: 0300  loss= 0.213926390  accuracy= 0.9380\n",
      "Step: 0400  loss= 0.179341301  accuracy= 0.9470\n",
      "Step: 0500  loss= 0.138849780  accuracy= 0.9595\n",
      "Step: 0600  loss= 0.117794424  accuracy= 0.9646\n",
      "Step: 0700  loss= 0.115002319  accuracy= 0.9665\n",
      "Step: 0800  loss= 0.106258400  accuracy= 0.9680\n",
      "Step: 0900  loss= 0.082878150  accuracy= 0.9752\n",
      "Step: 1000  loss= 0.080152862  accuracy= 0.9761\n"
     ]
    }
   ],
   "source": [
    "average_loss = 0.\n",
    "average_acc = 0.\n",
    "\n",
    "for step in range(num_steps):\n",
    "    d = dataset_iter.next()\n",
    "    x_batch = d[0]\n",
    "    y_batch = tf.cast(d[1],tf.int64)\n",
    "    \n",
    "    batch_loss = loss_fn(neural_net,x_batch,y_batch)\n",
    "    average_loss += batch_loss\n",
    "    \n",
    "    batch_accuracy = accuracy_fn(neural_net,x_batch,y_batch)\n",
    "    average_acc += batch_accuracy\n",
    "    \n",
    "    if step == 0:\n",
    "        print(\"Initial loss={:.9f}\".format(average_loss))\n",
    "    \n",
    "    optimizer.apply_gradients(grad(neural_net,x_batch,y_batch))\n",
    "    \n",
    "    if (step + 1) % display_step == 0 or step == 0:\n",
    "        if step > 0:\n",
    "            average_loss /= display_step\n",
    "            average_acc /= display_step\n",
    "        print(\"Step:\", '%04d' % (step + 1), \" loss=\",\n",
    "              \"{:.9f}\".format(average_loss), \" accuracy=\",\n",
    "              \"{:.4f}\".format(average_acc))\n",
    "        average_loss = 0.\n",
    "        average_acc = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset Accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "testX = mnist.test.images\n",
    "testY = mnist.test.labels\n",
    "\n",
    "test_acc = accuracy_fn(neural_net,testX,testY)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
